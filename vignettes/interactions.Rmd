---
title: "Interactions for Elicitation"
author: "Grace Heron, Jon Peppinck"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
%\VignetteIndexEntry{Interactions for Elicitation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  ---
  
  ```{r setup, include = FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
```

# R objects for building A-Frame Scenes with Interactive Entities

New additions to `r2vr` now include interactive entities that store the outputs into a database. So far there are two question types. The first is a binary question with options for `1` or `0` as responses. The second is a multivariable response question with four answer options. 
* `binary_question_scene()`
* `multivariable_question_scene()`


## Set up 

First you will need to install `ACEMS/r2vr` into your R library. Also you will need to set up a data base on [db4free](https://www.db4free.net/) with the same class name. For this example our class name is `koala`. 

Next you will need to know your local IP address on your computer. You can find this by opening a command window (cmd) and running the command `ipconfig`. The IP address next to `IPv4 Address` is what you need. 

```{r}
library(r2vr)
# Enter IP
IPv4_ADDRESS <- "131.181.64.15"
```

## Create experiment

You will need a folder of VR compatible images to use. Set up a variable that lists the paths to each image.

```{r}
img_paths <- c("../inst/ext/images/koalas/KP5.jpg", 
               "../inst/ext/images/koalas/SP10.jpg", 
               "../inst/ext/images/koalas/foundKoala1.jpg", 
               "../inst/ext/images/koalas/foundKoala2.jpg")
```

For this experiment we wish to ask a question with a yes or no answer so we will use `binary_question_scene()`. 

```{r}
animals <- binary_question_scene(
  the_question = "Do you see any koalas in this image?", # Our question
  answer_1 = "Yes",  # Text for '1'
  answer_2 = "No",   # Text for '0'
  img_paths = img_paths, # Image paths
  IPv4_ADDRESS = IPv4_ADDRESS, # Our local IP address
  animal_class = "koala" # Class name for database 
)
```

Let's start the VR server. Copy and paste your IP address into an internet browswer after running the below command.

```{r}
start(IPv4_ADDRESS)
```

Now the participant should be viewing the VR server in an internet browser on desktop or in a VR headset. Once the participant is immersed into the scene, we can now 'pop' the question. 

```{r}
pop()
```

The question and answer boxes should pop up on the displayed image. This command will only work once the scene is displayed. For the binary question, once an answer is selected it will be locked in so that answers are not duplicated for each participant for the same image. 

Next we will want to move to the next image with the below command.

```{r}
go(image_paths = img_paths, index = 2) # going to the second image
```

Again we pop the question and wait for the participant to answer.

```{r}
pop()
```

We can also 'unpop' to remove the question and answer boxes.

```{r}
pop(F)
```

When you are done with your image set, simply use the below command to close the server.

```{r}
end()
```

Time for the exciting part which is to import our elicitation data. Note that the end of the url is our animal class (koala). 

```{r}
# Get data from database with API GET request
koala.df <- read(url = "https://test-api-koala.herokuapp.com/koala")
koala.df
```

## Reef case study

Repeat for reef case study.

```{r}
# Define image paths
img_paths <- c("../inst/ext/images/reef/100030039.jpg", 
               "../inst/ext/images/reef/120261897.jpg", 
               "../inst/ext/images/reef/130030287.jpg", 
               "../inst/ext/images/reef/130050093.jpg")

## Create binary qestion scene for animals
animals <- binary_question_scene("Do the live corals on this reef form a structurally complex habitat?", "Yes", "No", img_paths, IPv4_ADDRESS, "reef")

## Launch VR server
start(IPv4_ADDRESS)

## Pop a question for first scene
pop()

## Move to new scene
go(image_paths = img_paths, index = 3)

## Don't forget to pop the question!
pop()

## Finish
end()

# Get data from database with API GET request
reef.df <- read(url = "https://test-api-koala.herokuapp.com/reef")
reef.df$recordedOn <-  ymd_hms(reef.df$recordedOn, tz = "Australia/Queensland")
reef.df
```

## Jaguar case study 

```{r}
# Define image paths
img_paths <- c("../inst/ext/images/jaguars/WP14_360_002.jpg", 
               "../inst/ext/images/jaguars/WP55_360_001.jpg", 
               "../inst/ext/images/jaguars/WP56_360_001.jpg",
               "../inst/ext/images/jaguars/WP60_360_001.jpg")


animals <- multivariable_question_scene("Do you see any of these habitat features in this image? If you do see a feature, click on the box to select it.",
                             "Water", "Jaguar tracks", "Scratch marks", "Dense Vegetation", img_paths, IPv4_ADDRESS)

## Launch VR server
start(IPv4_ADDRESS)

## Pop a question for first scene
pop(question_type = "multivariable")

## Move to new scene
go(image_paths = img_paths, index = 4, question_type = "multivariable")

## Don't forget to pop the question!
pop(question_type = "multivariable")

# Get data from database with API GET request
jaguar.df <- read(url = "https://test-api-koala.herokuapp.com/jaguar")
jaguar.df$recordedOn <-  ymd_hms(jaguar.df$recordedOn, tz = "Australia/Queensland")
jaguar.df
```